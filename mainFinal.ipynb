{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quaternion convolutional layers reproduction"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly I want to check if it possible to recreate the paper. This process will consist of the following steps\n",
    "\n",
    "- Dataloader\n",
    "- DataFormatter\n",
    "- QCNN import \n",
    "- QNN import\n",
    "- Recreate archtitecture \n",
    "- Train"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Questions for the following session\n",
    "\n",
    "- Where does the conversion to quaternions happen\n",
    "- When we input the output feautures map into the Qlinearlayer we lose all our information right\n",
    "- Why do de images needed te be padded with a extra dimension\n",
    "\n",
    "# To do following session\n",
    "\n",
    "- Train the network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modules\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch as th\n",
    "from torchvision import transforms\n",
    "import torchvision.datasets as datasets\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from torch.utils.data import DataLoader\n",
    "import core_qnn as qcnn\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from   torch.nn import Parameter\n",
    "from   torch.nn import functional as F\n",
    "import torch.optim\n",
    "from   torch.autograd import Variable\n",
    "from   torch import autograd\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "# Tranform data to PyTorch tensore\n",
    "from torchvision.utils import make_grid\n",
    "from torchvision.transforms import ToTensor\n",
    "import torchvision"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "grayscale = torchvision.transforms.Grayscale(num_output_channels=1)\n",
    "\n",
    "def convert_data_for_quaternion(batch):\n",
    "    \"\"\"\n",
    "    converts batches of RGB images in 4 channels for QNNs\n",
    "    \"\"\"\n",
    "    assert all(batch[i][0].size(0) == 3 for i in range(len(batch)))\n",
    "    inputs, labels = [], []\n",
    "    for i in range(len(batch)):\n",
    "        inputs.append(torch.cat([batch[i][0], torch.zeros(grayscale(batch[i][0]).size())], 0))\n",
    "        labels.append(batch[i][1])\n",
    "    \n",
    "    return torch.stack(inputs), torch.LongTensor(labels)\n",
    "\n",
    "transform_train = transforms.Compose(\n",
    "    [\n",
    "    transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),\n",
    "     transforms.RandomHorizontalFlip(),\n",
    "     transforms.ToTensor(),\n",
    "    #  transforms.Normalize((.5, .5, .5), (.5, .5, .5))\n",
    "     ])\n",
    "\n",
    "transform_test = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "    #  transforms.Normalize((.5, .5, .5), (.5, .5, .5))\n",
    "    ]\n",
    "     )\n",
    "\n",
    "data = datasets.CIFAR10(root='data', train=True, download=True, transform=transform_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = torch.utils.data.DataLoader(data, batch_size=32, shuffle=True,collate_fn=convert_data_for_quaternion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the size of image data torch.Size([4, 32, 32])\n",
      "This is the size of labels data torch.Size([32])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x24a9c8a41c0>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "iter_func = iter(loader)\n",
    "\n",
    "image_data, label_data = next(iter_func)\n",
    "\n",
    "print(\"This is the size of image data\",image_data[0].shape)\n",
    "\n",
    "print(\"This is the size of labels data\",label_data.shape)\n",
    "\n",
    "plt.imshow(image_data[0][:3,:,:].permute((2,1,0)), cmap='Greys_r')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0078, 0.0078, 0.0118,  ..., 0.0471, 0.0000, 0.0000],\n",
      "        [0.0157, 0.0078, 0.0078,  ..., 0.0471, 0.0000, 0.0000],\n",
      "        [0.0157, 0.0118, 0.0078,  ..., 0.1020, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.6627, 0.6078, 0.5961,  ..., 0.3843, 0.0000, 0.0000],\n",
      "        [0.7569, 0.7412, 0.7882,  ..., 0.3176, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]])\n"
     ]
    }
   ],
   "source": [
    "print(image_data[3][2,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from   core_qnn.quaternion_layers import QuaternionLinear, QuaternionTransposeConv, QuaternionConv\n",
    "\n",
    "class NormalModule(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(NormalModule, self).__init__()\n",
    "        \n",
    "        self.layer1 = nn.Linear(3072, 2048)\n",
    "        self.layer2 = nn.Linear(2048, 516)\n",
    "        self.layer3 = nn.Linear(516, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = th.flatten(x)\n",
    "        x = self.layer1.forward(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.layer2.forward(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.layer3.forward(x)\n",
    "        x = F.softmax(x)\n",
    "\n",
    "        return x\n",
    "    \n",
    "    def name(self):\n",
    "        return \"SimpleModule\"\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "class SimpleModule(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(SimpleModule, self).__init__()\n",
    "        \n",
    "        self.layer1 = QuaternionConv(in_channels=4, out_channels=4, kernel_size = 3, stride = 1, padding = 1)\n",
    "        self.layer2 = nn.Linear(4096, 516)\n",
    "        self.layer3 = nn.Linear(516, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layer1.forward(x)\n",
    "        x = F.relu(x)\n",
    "        x = th.flatten(x)\n",
    "        x = self.layer2.forward(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.layer3.forward(x)\n",
    "        x = F.softmax(x)\n",
    "\n",
    "        return x\n",
    "    \n",
    "    def name(self):\n",
    "        return \"SimpleModule\"\n",
    "    \n",
    "class TheModule(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(TheModule, self).__init__()\n",
    "        \n",
    "        self.layer1 = QuaternionConv(in_channels=4, out_channels=32, kernel_size = 3, stride = 1, padding = 1)\n",
    "        self.layer2 = QuaternionConv(in_channels=32, out_channels=32, kernel_size = 3, stride = 1, padding = 1)\n",
    "        self.layer3 = nn.MaxPool2d(kernel_size=2, stride = 2)\n",
    "        self.layer4 = nn.Dropout(0.25)\n",
    "\n",
    "        self.layer5 = QuaternionConv(in_channels=32, out_channels=64, kernel_size = 3, stride = 1, padding = 1)\n",
    "        self.layer6 = QuaternionConv(in_channels=64, out_channels=64, kernel_size = 3, stride = 1, padding = 1)\n",
    "\n",
    "        # self.layer7 = QuaternionLinear(4096, 512)\n",
    "        self.layer7 = nn.Linear(4096, 512)\n",
    "        \n",
    "        # self.layer8 = QuaternionLinear(512, 10)\n",
    "        self.layer8 = nn.Linear(512, 10)\n",
    "\n",
    "        self.layer9 = nn.Dropout(0.5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layer1.forward(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.layer2.forward(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.layer3(x)\n",
    "        # x = self.layer4(x)\n",
    "        \n",
    "        x = self.layer5.forward(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.layer6.forward(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.layer3(x)\n",
    "        # x = self.layer4(x) \n",
    "        \n",
    "        flat = nn.Flatten()\n",
    "        x = flat(x)\n",
    "        \n",
    "        x = self.layer7.forward(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.layer8.forward(x)\n",
    "        # x = self.layer9(x)\n",
    "        x = th.sigmoid(x)\n",
    "\n",
    "        return x\n",
    "    \n",
    "    def name(self):\n",
    "        return \"SimpleModule\"\n",
    "    \n",
    "class CNNModule(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(TheModule, self).__init__()\n",
    "        \n",
    "        self.layer1 = th.Conv2d(in_channels=3, out_channels=4, kernel_size = 3, stride = 1, padding = 1)\n",
    "        self.layer2 = th.Conv2d(in_channels=4, out_channels=1, kernel_size = 3, stride = 1, padding = 1)\n",
    "        self.layer3 = nn.MaxPool2d(kernel_size=2, stride = 2)\n",
    "        self.layer4 = nn.Dropout(0.25)\n",
    "\n",
    "        self.layer5 = th.Conv2d(in_channels=1, out_channels=2, kernel_size = 3, stride = 1, padding = 1)\n",
    "        self.layer6 = th.Conv2d(in_channels=2, out_channels=1, kernel_size = 3, stride = 1, padding = 1)\n",
    "\n",
    "        # self.layer7 = QuaternionLinear(4096, 512)\n",
    "        self.layer7 = nn.Linear(4096, 512)\n",
    "        \n",
    "        # self.layer8 = QuaternionLinear(512, 10)\n",
    "        self.layer8 = nn.Linear(512, 10)\n",
    "\n",
    "        self.layer9 = nn.Dropout(0.5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layer1.forward(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.layer2.forward(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.layer3(x)\n",
    "        # x = self.layer4(x)\n",
    "        \n",
    "        x = self.layer5.forward(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.layer6.forward(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.layer3(x)\n",
    "        # x = self.layer4(x) \n",
    "        \n",
    "        flat = nn.Flatten()\n",
    "        x = flat(x)\n",
    "        \n",
    "        x = self.layer7.forward(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.layer8.forward(x)\n",
    "        # x = self.layer9(x)\n",
    "        x = th.sigmoid(x)\n",
    "\n",
    "        return x\n",
    "    \n",
    "    def name(self):\n",
    "        return \"SimpleModule\"\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choose your network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose your model\n",
    "if False: model = SimpleModule().cuda(); \n",
    "if True: model = TheModule().cuda(); \n",
    "if False: model = CNNModule().cuda(); \n",
    "if False: model = NormalModule().cuda(); \n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "opt = torch.optim.RMSprop(model.parameters(), lr = 0.0001,weight_decay=1e-6)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the network \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/80], Loss: 1.9551\n",
      "Epoch [2/80], Loss: 1.7628\n",
      "Epoch [3/80], Loss: 1.9730\n",
      "Epoch [4/80], Loss: 1.9169\n",
      "Epoch [5/80], Loss: 2.0855\n",
      "Epoch [6/80], Loss: 1.8613\n",
      "Epoch [7/80], Loss: 1.7134\n",
      "Epoch [8/80], Loss: 1.9092\n",
      "Epoch [9/80], Loss: 1.9186\n",
      "Epoch [10/80], Loss: 1.9188\n",
      "Epoch [11/80], Loss: 1.7378\n",
      "Epoch [12/80], Loss: 1.9982\n",
      "Epoch [13/80], Loss: 1.7211\n",
      "Epoch [14/80], Loss: 1.9288\n",
      "Epoch [15/80], Loss: 1.7429\n",
      "Epoch [16/80], Loss: 1.8527\n",
      "Epoch [17/80], Loss: 1.7955\n",
      "Epoch [18/80], Loss: 1.8267\n",
      "Epoch [19/80], Loss: 1.8764\n",
      "Epoch [20/80], Loss: 1.7039\n",
      "Epoch [21/80], Loss: 1.7115\n",
      "Epoch [22/80], Loss: 1.8561\n",
      "Epoch [23/80], Loss: 1.8491\n",
      "Epoch [24/80], Loss: 1.7731\n",
      "Epoch [25/80], Loss: 1.8801\n",
      "Epoch [26/80], Loss: 1.7887\n",
      "Epoch [27/80], Loss: 1.8222\n",
      "Epoch [28/80], Loss: 1.7490\n",
      "Epoch [29/80], Loss: 1.7571\n",
      "Epoch [30/80], Loss: 1.5362\n",
      "Epoch [31/80], Loss: 1.7561\n",
      "Epoch [32/80], Loss: 1.6665\n",
      "Epoch [33/80], Loss: 1.7284\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 80\n",
    "losses = []\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for inputs, labels in loader:\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = inputs.to('cuda'), labels.to('cuda')\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        opt.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "        # print statistics\n",
    "            # Print progress\n",
    "    if (epoch+1) % 1 == 0:\n",
    "        losses.append(loss.cpu().item())\n",
    "        print ('Epoch [{}/{}], Loss: {:.4f}'\n",
    "            .format(epoch+1, num_epochs, loss.cpu().item()))\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting the data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(len(losses)), losses)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "data_test = datasets.CIFAR10(root='data', train=False, download=True, transform=transform_test)\n",
    "testloader = torch.utils.data.DataLoader(data_test, batch_size=10000, shuffle=False, \\\n",
    "    collate_fn=convert_data_for_quaternion)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "x = datetime.datetime.now()\n",
    "appendix = \"As proposed in the paper\"\n",
    "string = str(x.day) + \"_\" + str(x.hour) + \"_\" + str(x.minute) + \"_\" + str(x.second) + \"_\" + str(appendix)\n",
    "torch.save(model.state_dict(), f\"./modelsParameters/{string}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TheModule(\n",
       "  (layer1): QuaternionConv(in_channels=1, out_channels=8, bias=True, kernel_size=(3, 3), stride=1, padding=1, init_criterion=glorot, weight_init=quaternion, seed=636, rotation=False, q_format=True, operation=convolution2d)\n",
       "  (layer2): QuaternionConv(in_channels=8, out_channels=8, bias=True, kernel_size=(3, 3), stride=1, padding=1, init_criterion=glorot, weight_init=quaternion, seed=282, rotation=False, q_format=True, operation=convolution2d)\n",
       "  (layer3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (layer4): Dropout(p=0.25, inplace=False)\n",
       "  (layer5): QuaternionConv(in_channels=8, out_channels=16, bias=True, kernel_size=(3, 3), stride=1, padding=1, init_criterion=glorot, weight_init=quaternion, seed=1001, rotation=False, q_format=True, operation=convolution2d)\n",
       "  (layer6): QuaternionConv(in_channels=16, out_channels=16, bias=True, kernel_size=(3, 3), stride=1, padding=1, init_criterion=glorot, weight_init=quaternion, seed=802, rotation=False, q_format=True, operation=convolution2d)\n",
       "  (layer7): QuaternionLinear(in_features=1024, out_features=128, bias=True, init_criterion=he, weight_init=quaternion, seed=841)\n",
       "  (layer8): Linear(in_features=512, out_features=10, bias=True)\n",
       "  (layer9): Dropout(p=0.5, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = TheModule().cuda()\n",
    "model.load_state_dict(torch.load(\"./hoi\"))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 9.6100%\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "# since we're not training, we don't need to calculate the gradients for our outputs\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in testloader:\n",
    "        images, labels = inputs.to('cuda'), labels.to('cuda')\n",
    "        # calculate outputs by running images through the network\n",
    "        outputs = model(images)\n",
    "        # the class with the highest energy is what we choose as prediction\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "print(f'Accuracy of the network on the 10000 test images: {100 * correct / total:.4f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
